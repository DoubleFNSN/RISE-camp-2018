# About
This repo contains the materials gathered from Berkley Rise camp.

# Quick description of each event/product:
* Ray: Distributed framework for executing python codes (you can split tasks to multiple cpu/gpu or even node). This makes ML faster.
* Ray Tune: Helps scale model training
* Clipper: Helps package models in container and allows serving this in scale.
* Flor: helps version ML/AI experiments.


# Agenda

9:00AM: Tutorial overview  [Ionel Gog]
9:15AM: Ray: Distributed Execution Framework for Emerging AI Applications
9:15 – ­9:45AM: Ray Talk [Phillip Moritz]
9:45 – ­11:00AM: Ray Tutorial Lab
11:00AM: Break
11:30AM: RLlib: Ray Reinforcement Learning Library
11:30 – ­11:45AM RLlib Talk [Eric Liang]
11:45 – 12:45PM RLlib Tutorial Lab
12:45 – 1:45PM: Lunch
1:45 PM: Tune: Hyperparameter search
1:45 – ­2:00PM Tune Talk [Richard Liaw]
2:00 – 3:00PM Tune Tutorial Lab
3:00PM: Clipper: a Low-Latency Online Prediction Serving System
3:00 – ­3:30PM: Clipper Talk [Simon Mo]
3:30 – ­4:30PM: Clipper Tutorial Lab
4:30­PM: Break
5:00PM: ML in Context: Preserve, Share, and Analyze Experiments with Flor
5:00-5:30PM: Flor Talk [Rolando Garcia]
5:30-6:30PM: Flor Tutorial Lab
6:30­ – 9:00PM: Reception


# Project resources
### Ray:
Documentation: http://ray.readthedocs.io/en/latest/index.html

Code: https://github.com/ray-project/ray

Tutorial: https://github.com/ray-project/tutorial




### Tune
Tune is a scalable framework for model training and hyperparameter search with a focus on deep learning and deep reinforcement learning.

Code: https://github.com/ray-project/ray/tree/master/python/ray/tune

Examples: https://github.com/ray-project/ray/tree/master/python/ray/tune/examples

Documentation: http://ray.readthedocs.io/en/latest/tune.html



### Flor
Project page: https://github.com/ucbrise/flor
