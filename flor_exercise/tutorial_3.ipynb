{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Finer-Grained Annotation and Versioning\n",
    "\n",
    "Now that we've learned how to use Flor's extended syntax, we will annotate and version the experiment we have been developing to capture more detailed context about the inputs, code and outputs.\n",
    "\n",
    "Goals of this notebook:\n",
    "- Factor our monolithic training script into 3 encapsulated Flor Actions, which pass Artifacts and Literals between them that can be tracked by Flor\n",
    "- Connect our Actions and Artifacts into a *Flor Plan* workflow DAG\n",
    "- See how previously derived Artifacts can be reused without rerunning monolithic scripts\n",
    "- Query Flor's automatically-tracked context to identify and serve our best model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare your environment before starting the activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we're going to start by importing Flor and letting it know the name of our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Flor\n",
    "import flor\n",
    "\n",
    "# If the notebook name has not already been set, you are able to set the name in code. \n",
    "flor.setNotebookName('tutorial_3.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll provide Flor annotations for all our code in advance\n",
    "\n",
    "Before we can put together a multi-step experiment in Flor, we need to define the individual Flor functions for each step. The next 3 code cells correspond to 3 Flor actions that we will compose into a *Flor plan* below.\n",
    "\n",
    "Our first action, shown in the next cell, takes care of splitting the data. `split` is our first \"encapsulated\" Flor function, and it's useful to spend some time understanding its arguments and how they are used. When we compose `split` in our Flor plan below, we'll see that:\n",
    "- `intermediate_X` and `intermediate_y` are input Flor Artifacts -- references to files (of data). The `split` routine makes standard Python I/O calls on these (lines 7-14, 19-27) as it would with any file handles, but Flor is able to track the versions of these files during each experiment run.\n",
    "- `test_size` and `random_state` are input Flor Literals -- passed by value. Note that both of these Literals are passed in the subroutine call to `train_test_split` in Line 17; Flor will be able to track the versions of these Literals as they pass through code during an experiment run. \n",
    "- `X_train`, `X_test`, `y_train` and `y_test` are Flor Artifacts that represent the *output* of this function; again they will be tracked by Flor in each experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def split(intermediate_X, intermediate_y, test_size, random_state, \n",
    "          X_train, X_test, y_train, y_test, **kwargs):\n",
    "    import json\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Read the inputs\n",
    "    with open(intermediate_X) as json_data:\n",
    "        X = json.load(json_data)\n",
    "        json_data.close()\n",
    "        \n",
    "    with open(intermediate_y) as json_data:\n",
    "        y = json.load(json_data)\n",
    "        json_data.close()\n",
    "        \n",
    "    # Split the data\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Write the outputs\n",
    "    with open(X_train, 'w') as f:\n",
    "        json.dump(X_tr, f)\n",
    "    with open(X_test, 'w') as f:\n",
    "        json.dump(X_te, f)\n",
    "    with open(y_train, 'w') as f:\n",
    "        json.dump(y_tr, f)\n",
    "    with open(y_test, 'w') as f:\n",
    "        json.dump(y_te, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, notice the input parameters include `X_train` and `y_train`, which we will use to pass in the output Artifacts from the previous cell's `split` function. `model` and `vectorizer` are output Artifacts of the `train` function below; they are written into files in Lines 26-30, containing serialized Python objects that will also be tracked by Flor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def train(X_train, y_train, n_estimators, max_depth, model, vectorizer, **kwargs):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import cloudpickle\n",
    "\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    # Read the inputs\n",
    "    with open(X_train, 'r') as f:\n",
    "        X_tr = json.load(f)\n",
    "    with open(y_train, 'r') as f:\n",
    "        y_tr = json.load(f)\n",
    "    \n",
    "    # Fit the vectorizer\n",
    "    vec = TfidfVectorizer()\n",
    "    vec.fit(X_tr)\n",
    "    \n",
    "    # Transform the training data\n",
    "    X_tr = vec.transform(X_tr)\n",
    "    \n",
    "    # Train the model\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth).fit(X_tr, y_tr)\n",
    "    \n",
    "    # Write the output\n",
    "    with open(model, 'wb') as f:\n",
    "        cloudpickle.dump(clf, f)\n",
    "    with open(vectorizer, 'wb') as f:\n",
    "        cloudpickle.dump(vec, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the `eval` function below takes as arguments the test data, model, and vectorizer Artifacts and evaluates the model we just trained. Note line 24: the `return` of a Flor func is a Flor Literal that is tracked in each experiment run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@flor.func\n",
    "def eval(X_test, y_test, model, vectorizer, **kwargs):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    import cloudpickle\n",
    "    \n",
    "    # Read the inputs\n",
    "    with open(X_test, 'r') as f:\n",
    "        X_te = json.load(f)\n",
    "    with open(y_test, 'r') as f:\n",
    "        y_te = json.load(f)\n",
    "    with open(model, 'rb') as f:\n",
    "        clf = cloudpickle.load(f)\n",
    "    with open(vectorizer, 'rb') as f:\n",
    "        vec = cloudpickle.load(f)\n",
    "    \n",
    "    # Test the model\n",
    "    X_te = vec.transform(X_te)\n",
    "    score = clf.score(X_te, y_te)\n",
    "    \n",
    "    print(score)\n",
    "    \n",
    "    # Return the score\n",
    "    return {'score': score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's build a detailed Flor Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've written the code, and we know which resources to read (Bob's latest preprocessed data), we can specify the Flor Plan, exposing all hyper-parameters and intermediate Artifacts. \n",
    "\n",
    "Look at lines 13-19; they wire the `split` Action into the Flor plan with its inputs and outputs. The inputs are declared in the `in_artifacts` parameter to `ex.action` in line 13. Each of lines 14-17 specifies an output Artifact; we connect that Artifact to a specific argument of the `split` Action by (a) referencing `do_split` in the `parent` argument to `ex.artifact`, and (b) declaring the desired argument of `split` via the `name` argument of `ex.artifact`.\n",
    "\n",
    "A similar pattern wires in `train` in lines 19-21, and `eval` in lines 23-24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with flor.Experiment('bob_preproc') as bob, flor.Experiment('risecamp_demo') as ex:\n",
    "    # This is how we tell Flor we will be using Bob's derived artifacts\n",
    "    data_x = bob.artifact('data_clean_X.json', 'intermediate_X', label=\"second_preproc\")\n",
    "    data_y = bob.artifact('data_clean_y.json', 'intermediate_y', label=\"second_preproc\")\n",
    "    \n",
    "    # Here we declare all the static literals\n",
    "    random_state = ex.literal(92, 'random_state')\n",
    "    test_size = ex.literal(0.20, 'test_size')\n",
    "    n_estimators = ex.literal(7, 'n_estimators') \n",
    "    max_depth = ex.literal(100, 'max_depth')\n",
    "    \n",
    "    # Now we connect the Flor Plan\n",
    "    do_split = ex.action(func=split, in_artifacts=[data_x, data_y, test_size, random_state])\n",
    "    X_train = ex.artifact(loc='X_train.json', name='X_train', parent=do_split)\n",
    "    X_test = ex.artifact(loc='X_test.json', name='X_test', parent=do_split)\n",
    "    y_train = ex.artifact(loc='y_train.json', name='y_train', parent=do_split)\n",
    "    y_test = ex.artifact(loc='y_test.json', name='y_test', parent=do_split)\n",
    "    \n",
    "    do_train = ex.action(func=train, in_artifacts=[X_train, y_train, n_estimators, max_depth])\n",
    "    model = ex.artifact(loc='model.pkl', name='model', parent=do_train)\n",
    "    vectorizer = ex.artifact(loc='vectorizer.pkl', name='vectorizer', parent=do_train)\n",
    "    \n",
    "    do_eval = ex.action(func=eval, in_artifacts=[X_test, y_test, model, vectorizer])\n",
    "    score = ex.literal(name='score', parent=do_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to this point, we only saw Flor Plans with a single action. Now we can call `score.plot()` to see our more involved Flor Plan.  In the plot generated by the next cell, rectangles correspond to Artifacts, which the user is responsible for reading/writing, but which Flor automatically tracks and versions. The underlined names correspond to literals, which Flor both stores and tracks across runs. \n",
    "\n",
    "The distinction between Artifacts and Literals can sometimes feel arbitrary. As a rule of thumb, if an object is relatively small (in bytes) and can be serialized as a string without losing information, then it can be a Literal. Otherwise, it's best to represent it as an Artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: source Pages: 1 -->\n",
       "<svg width=\"520pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 520.00 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>source</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-472 516,-472 516,4 -4,4\"/>\n",
       "<!-- 2 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"72,-468 0,-468 0,-432 72,-432 72,-468\"/>\n",
       "<text text-anchor=\"middle\" x=\"36\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">tutorial_3</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"277\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">eval</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M32.0632,-431.9156C26.498,-404.7281 17,-351.6422 17,-306 17,-306 17,-306 17,-234 17,-133.1792 168.461,-102.3742 240.1794,-93.439\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"240.6284,-96.9104 250.1547,-92.2736 239.8161,-89.9577 240.6284,-96.9104\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"263\" cy=\"-378\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"263\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">split</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;7 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M72.2412,-435.1709C75.1923,-434.065 78.1387,-432.9944 81,-432 131.5109,-414.4462 191.1006,-397.4525 227.9727,-387.3598\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"229.0133,-390.704 237.7436,-384.7014 227.1755,-383.9496 229.0133,-390.704\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"196\" cy=\"-234\" rx=\"27.0966\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">train</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;14 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M35.2916,-431.9314C34.9833,-399.3855 38.8745,-330.3646 74,-288 95.4992,-262.07 131.9406,-248.1743 159.4108,-241.0078\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"160.553,-244.3325 169.4499,-238.5796 158.9073,-237.5287 160.553,-244.3325\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>8</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"194,-468 90,-468 90,-432 194,-432 194,-468\"/>\n",
       "<text text-anchor=\"middle\" x=\"142\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_X</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;7 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>8&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M172.5334,-431.8314C191.4252,-420.5899 215.5325,-406.2451 234.1101,-395.1907\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"235.9349,-398.1777 242.7388,-390.0563 232.3553,-392.1621 235.9349,-398.1777\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>9</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"313.5,-468 212.5,-468 212.5,-432 313.5,-432 313.5,-468\"/>\n",
       "<text text-anchor=\"middle\" x=\"263\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">intermediate_y</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;7 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>9&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M263,-431.8314C263,-424.131 263,-414.9743 263,-406.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"266.5001,-406.4132 263,-396.4133 259.5001,-406.4133 266.5001,-406.4132\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>10</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"396,-468 332,-468 332,-432 396,-432 396,-468\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"332,-432 396,-432 \"/>\n",
       "<text text-anchor=\"middle\" x=\"364\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">test_size</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;7 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>10&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M338.5134,-431.8314C323.6628,-421.2448 304.9512,-407.9058 289.8698,-397.1547\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"291.6407,-394.1188 281.4662,-391.164 287.5773,-399.8188 291.6407,-394.1188\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>11</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"507.5,-468 414.5,-468 414.5,-432 507.5,-432 507.5,-468\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"414.5,-432 507.5,-432 \"/>\n",
       "<text text-anchor=\"middle\" x=\"461\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">random_state</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>11&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M414.3275,-433.0282C378.0631,-419.8411 328.653,-401.8738 296.3028,-390.1101\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"297.4383,-386.7988 286.8442,-386.6706 295.046,-393.3774 297.4383,-386.7988\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>15</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"325.5,-324 236.5,-324 236.5,-288 325.5,-288 325.5,-324\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"236.5,-288 325.5,-288 \"/>\n",
       "<text text-anchor=\"middle\" x=\"281\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">n_estimators</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;14 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>15&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M259.5509,-287.8314C247.6899,-277.7844 232.9024,-265.2585 220.577,-254.8182\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"222.7812,-252.0984 212.8885,-248.3056 218.2568,-257.4397 222.7812,-252.0984\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>16</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"424.5,-324 343.5,-324 343.5,-288 424.5,-288 424.5,-324\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"343.5,-288 424.5,-288 \"/>\n",
       "<text text-anchor=\"middle\" x=\"384\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">max_depth</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;14 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>16&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M343.2068,-290.3771C309.1979,-277.3524 261.3343,-259.0216 229.5254,-246.8395\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"230.3903,-243.4229 219.7999,-243.1149 227.8867,-249.9599 230.3903,-243.4229\"/>\n",
       "</g>\n",
       "<!-- 0 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"transparent\" points=\"304,-36 250,-36 250,0 304,0 304,-36\"/>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"250,0 304,0 \"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">score</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277,-71.8314C277,-64.131 277,-54.9743 277,-46.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.5001,-46.4132 277,-36.4133 273.5001,-46.4133 280.5001,-46.4132\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"143,-324 83,-324 83,-288 143,-288 143,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"113\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X_train</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;3 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>7&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M240.867,-367.3762C217.6571,-356.2354 180.7035,-338.4977 152.478,-324.9494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"153.8028,-321.703 143.2729,-320.531 150.7736,-328.0137 153.8028,-321.703\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"394,-252 340,-252 340,-216 394,-216 394,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"367\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">X_test</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M289.4719,-373.5267C333.0353,-365.5662 416.7468,-347.5414 434,-324 443.4581,-311.0948 440.9048,-302.4334 434,-288 427.2949,-273.9841 414.98,-262.444 402.72,-253.6813\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"404.5699,-250.7079 394.3107,-248.0622 400.6808,-256.5282 404.5699,-250.7079\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"218.5,-324 161.5,-324 161.5,-288 218.5,-288 218.5,-324\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_train</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;5 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>7&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M247.8744,-363.0816C238.5771,-353.9116 226.4231,-341.9241 215.6544,-331.3029\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.05,-328.7498 208.4726,-324.2195 213.1345,-333.7336 218.05,-328.7498\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"512,-252 458,-252 458,-216 512,-216 512,-252\"/>\n",
       "<text text-anchor=\"middle\" x=\"485\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">y_test</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;6 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>7&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M289.3141,-373.4426C335.2099,-365.0188 427.2779,-345.8635 451,-324 468.3862,-307.976 476.9407,-282.1542 481.1145,-262.2699\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"484.597,-262.6841 482.9663,-252.2156 477.7128,-261.4162 484.597,-262.6841\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>12</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"304,-180 250,-180 250,-144 304,-144 304,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"277\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">model</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;12 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>14&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M212.3916,-219.4297C222.8577,-210.1265 236.7012,-197.8212 248.8885,-186.988\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"251.4572,-189.3876 256.606,-180.128 246.8066,-184.1557 251.4572,-189.3876\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>13</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"232,-180 160,-180 160,-144 232,-144 232,-180\"/>\n",
       "<text text-anchor=\"middle\" x=\"196\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">vectorizer</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;13 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>14&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M196,-215.8314C196,-208.131 196,-198.9743 196,-190.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"199.5001,-190.4132 196,-180.4133 192.5001,-190.4133 199.5001,-190.4132\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;14 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>3&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M133.9444,-287.8314C145.338,-277.9478 159.4971,-265.6652 171.4123,-255.3291\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.9807,-257.7344 179.2412,-248.5378 169.3938,-252.4467 173.9807,-257.7344\"/>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;1 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>4&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M356.4913,-215.9168C345.7866,-197.6333 328.5905,-168.6361 313,-144 306.9447,-134.4314 300.0955,-124.0533 294.009,-114.9759\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.7265,-112.7455 288.2344,-106.4104 290.9223,-116.6586 296.7265,-112.7455\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;14 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>5&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M191.5141,-287.8314C192.1558,-280.131 192.9188,-270.9743 193.6319,-262.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"197.1229,-262.6694 194.4656,-252.4133 190.1471,-262.088 197.1229,-262.6694\"/>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;1 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>6&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M458.6567,-215.7623C418.9377,-188.2646 344.1093,-136.4603 304.0047,-108.6956\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.9793,-105.8057 295.7651,-102.9912 301.9948,-111.561 305.9793,-105.8057\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;1 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>12&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M277,-143.8314C277,-136.131 277,-126.9743 277,-118.4166\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"280.5001,-118.4132 277,-108.4133 273.5001,-118.4133 280.5001,-118.4132\"/>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;1 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>13&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M216.4397,-143.8314C227.5588,-133.9478 241.3767,-121.6652 253.0047,-111.3291\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"255.4962,-113.7974 260.645,-104.5378 250.8456,-108.5655 255.4962,-113.7974\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f63be091550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pull the score to execute the experiment we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7567\n"
     ]
    }
   ],
   "source": [
    "score.pull('seventh_pull')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the score is still hovering around 75%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>score</th>\n",
       "      <th>random_state</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>test_size</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>tutorial_3</th>\n",
       "      <th>y_train</th>\n",
       "      <th>y_test</th>\n",
       "      <th>X_test</th>\n",
       "      <th>intermediate_X</th>\n",
       "      <th>intermediate_y</th>\n",
       "      <th>X_train</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>model</th>\n",
       "      <th>tutorial_2</th>\n",
       "      <th>tutorial_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seventh_pull</td>\n",
       "      <td>0.7567</td>\n",
       "      <td>92.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>tutorial_3_140066367161288.ipynb</td>\n",
       "      <td>y_train_140066367161736.json</td>\n",
       "      <td>y_test_140066367162072.json</td>\n",
       "      <td>X_test_140066367162408.json</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>X_train_140066367161232.json</td>\n",
       "      <td>vectorizer_140066367160896.pkl</td>\n",
       "      <td>model_140066367160728.pkl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sixth_pull</td>\n",
       "      <td>0.7460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data_clean_X_112394722104.json</td>\n",
       "      <td>data_clean_y_112394719416.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_2_140276092881104.ipynb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fifth_pull</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>data_clean_X_111988783760.json</td>\n",
       "      <td>data_clean_y_111988784208.json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_2_140276092876728.ipynb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-12_00-42-25</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_1_139742951853808.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-12_00-42-25</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_1_139742951853808.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-10-12_00-38-58</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_1_139742745119600.ipynb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-10-12_00-37-29</td>\n",
       "      <td>0.7044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tutorial_1_139741553533616.ipynb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label   score  random_state  n_estimators  test_size  \\\n",
       "0         seventh_pull  0.7567          92.0           7.0        0.2   \n",
       "1           sixth_pull  0.7460           NaN           7.0        NaN   \n",
       "2           fifth_pull  0.6520           NaN           7.0        NaN   \n",
       "3  2018-10-12_00-42-25  0.7331           NaN           7.0        NaN   \n",
       "4  2018-10-12_00-42-25  0.7002           NaN           7.0        NaN   \n",
       "5  2018-10-12_00-38-58  0.7089           NaN           NaN        NaN   \n",
       "6  2018-10-12_00-37-29  0.7044           NaN           NaN        NaN   \n",
       "\n",
       "   max_depth                        tutorial_3                       y_train  \\\n",
       "0      100.0  tutorial_3_140066367161288.ipynb  y_train_140066367161736.json   \n",
       "1      100.0                               NaN                           NaN   \n",
       "2      100.0                               NaN                           NaN   \n",
       "3      100.0                               NaN                           NaN   \n",
       "4       10.0                               NaN                           NaN   \n",
       "5        NaN                               NaN                           NaN   \n",
       "6        NaN                               NaN                           NaN   \n",
       "\n",
       "                        y_test                       X_test  \\\n",
       "0  y_test_140066367162072.json  X_test_140066367162408.json   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "5                          NaN                          NaN   \n",
       "6                          NaN                          NaN   \n",
       "\n",
       "                   intermediate_X                  intermediate_y  \\\n",
       "0  data_clean_X_112394722104.json  data_clean_y_112394719416.json   \n",
       "1  data_clean_X_112394722104.json  data_clean_y_112394719416.json   \n",
       "2  data_clean_X_111988783760.json  data_clean_y_111988784208.json   \n",
       "3                             NaN                             NaN   \n",
       "4                             NaN                             NaN   \n",
       "5                             NaN                             NaN   \n",
       "6                             NaN                             NaN   \n",
       "\n",
       "                        X_train                      vectorizer  \\\n",
       "0  X_train_140066367161232.json  vectorizer_140066367160896.pkl   \n",
       "1                           NaN                             NaN   \n",
       "2                           NaN                             NaN   \n",
       "3                           NaN                             NaN   \n",
       "4                           NaN                             NaN   \n",
       "5                           NaN                             NaN   \n",
       "6                           NaN                             NaN   \n",
       "\n",
       "                       model                        tutorial_2  \\\n",
       "0  model_140066367160728.pkl                               NaN   \n",
       "1                        NaN  tutorial_2_140276092881104.ipynb   \n",
       "2                        NaN  tutorial_2_140276092876728.ipynb   \n",
       "3                        NaN                               NaN   \n",
       "4                        NaN                               NaN   \n",
       "5                        NaN                               NaN   \n",
       "6                        NaN                               NaN   \n",
       "\n",
       "                         tutorial_1  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3  tutorial_1_139742951853808.ipynb  \n",
       "4  tutorial_1_139742951853808.ipynb  \n",
       "5  tutorial_1_139742745119600.ipynb  \n",
       "6  tutorial_1_139741553533616.ipynb  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flor.Experiment('risecamp_demo').summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the finer-grained annotations resulted in more detailed information about our experimental pipeline. The Flor plan itself is a more helpful description of the high-level intent of the code, and serves as a form of documentation. Also, because Flor is tracking intermediate Artifacts and Literals, the `summarize` call is able to provide more information about what is computed and stored along the way. These intermediate Artifacts and Literals are automatically versioned by Flor, and can be individually examined and `diff`ed across runs for more granular tracking of changes across runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing models from previous Flor experiments\n",
    "Another benefit of exposing the intermediate Artifacts and Literals between smaller Actions is that previously-computer intermediate objects can be reused without requiring recomputation. In the next cells we will reuse the output Artifacts from our earlier runs, examine them, and \"serve\" them in a toy application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkout best model and serve it\n",
    "Here, we're going to retrieve the model and vectorizer we just fitted with Flor. Lines 1-3 of the next cell declare a Flor experiment in the extended syntax. In lines 4-5, rather than calling the Flor `pull` method (which runs an experiment and stores the output) we use Flor's `peek` method to build each Artifact and load it into a Python variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with flor.Experiment('risecamp_demo') as ex:\n",
    "    model = ex.artifact('model.pkl', 'model', label='seventh_pull')\n",
    "    vectorizer = ex.artifact('vectorizer.pkl', 'vectorizer', label='seventh_pull')\n",
    "model = model.peek()\n",
    "vec = vectorizer.peek()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we deploy the model into a toy application that tries to predict the sentiment from your phrases. Try out some phrases and see how the model does!  Enter `nothing` to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What's on your mind? \"\n",
    "\n",
    "phrase = input(PROMPT)\n",
    "while phrase[0:len('nothing')].lower() != 'nothing':\n",
    "    phrase = vec.transform([phrase,])\n",
    "    positive = model.predict(phrase)\n",
    "    if positive:\n",
    "        print('Happy to hear that!\\n'.format(phrase))\n",
    "    else:\n",
    "        print(\"Sorry about that...\\n\")\n",
    "    phrase = input(PROMPT)\n",
    "print('you said nothing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Thoughts\n",
    "To summarize our three notebooks, we've been reminded of the value of annotating and versioning experiments, and witnessed how Flor can automate these responsibilities with as few as 3 lines of code. Moreover, when finer-grained tracking is desired, Flor is able to capture more meta-data and store derived artifacts for future retrieval. Flor enables experiment interpretation and re-using artifacts across experiments."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
